---
title: "Scripps's Murrelet Egg Size model"
author: "Amelia J. DuVall & Marcela Todd"
date: "4/11/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

## load libraries
library(here)
library(tidyverse)
library(janitor)
library(ggplot2)
library(lubridate)
library(viridis)
library(lme4)
library(faraway)
library(sjPlot)
```

This is `r paste0("v.", (Sys.Date()))`

#TODO
- Test lag on environmental covariates
- Model averaging prediction for top 3 models
- 

# Introduction
This document details steps taken to model Scripps's Murrelet (*Synthliboramphus scrippsi*) egg size at Santa Barbara Island within Channel Islands National Park from 2009-2017.  

# Load and format data 
```{r data}
egg <- read.csv(here("data", "SCMU_egg_data.csv")) 
covars <- read.csv(here("data", "covariates", "covars.csv"))

## join covariate data with egg data by year
SCMUdf <- left_join(egg, covars, by = "Year") %>%
  filter(TrueOrder == TRUE) %>% # egg order known only
  select(Year, Observer, Plot, Size, EggOrder, ANCHL, BEUTI, NPGO, ONI, PDO, SST) %>%
  as_tibble()
```

# Null Intercept-Only Model
This model includes observer and plot as random effects, but does not include any covariates.
```{r null_model}
## run model
nm <- lmer(Size ~ 1 + (1 | Observer) + (1 | Plot), data = SCMUdf, REML = TRUE)

## look at model output and estimates
sumary(nm)
coef(nm) # these are the coefficients
ranef(nm) # these are the random effects
## you can store the model results to objects
obs.ranef <- ranef(nm)$Observer 
plot.ranef <- ranef(nm)$Plot
## the mean of these values should be close to 0
mean(obs.ranef[[1]])
mean(plot.ranef[[1]])

## quick model diagnostics
## extract predicted values and plot
preds <- predict(nm) 
ggplot() + 
  geom_histogram(mapping = aes(preds)) + 
  theme_minimal() 
# we want these to look normally distributed

## extract residuals and plot
resids <- residuals(nm) 
ggplot() + 
  geom_histogram(mapping = aes(resids)) + 
  theme_minimal()
# we want these to look normally distributed

## Q-Q Plots
# ## set plot area
# par(mai = c(0.9, 0.9, 0.6, 0.1),
#     omi = c(0, 0, 0, 0),
#     mfrow = c(1,2), cex.lab = 1.2)

# qq resids
qqnorm(resids, main = "QQ plot (residuals)", las = 1, pch = 16)
qqline(resids)

## plot residuals versus fitted values
yh <- fitted(nm)
plot(yh, resids, las = 1, pch = 16,
     xlab = "Fitted", ylab = "Residuals",
     main = "Residuals vs fitted")
abline(h=0, lty = "dashed")
```

# Egg Order-only Model
This model includes observer and plot as random effects and egg order as a fixed effect. 
```{r egg_model}
## run the model
order.mod <- lmer(Size ~ EggOrder + (1 | Observer) + (1 | Plot), data = SCMUdf, REML = TRUE)

## look at model summary and estimates
sumary(order.mod)
coef(summary(order.mod))
VarCorr(order.mod)
ranef(order.mod)
```

# Fit Candidate Models
```{r mods}
## create data frame specifying predictors to include
predictors <- as.data.frame(matrix(c(FALSE, TRUE), 2, 7)) # 7 potential predictors (includes EggOrder)

## add column names
cov_names <- colnames(predictors) <- colnames(SCMUdf[,5:11])

## create set of all possible combinations
full_set <- expand.grid(predictors) # 128 combinations

## select models with correlated predictors
ii <- which(full_set$ANCHL + full_set$NPGO == 2 |
              full_set$BEUTI + full_set$PDO == 2 |
              full_set$NPGO + full_set$SST == 2 |
              full_set$ONI + full_set$PDO == 2 |
              full_set$ONI + full_set$SST == 2 |
              full_set$PDO + full_set$SST == 2 ) # 90 models

## create reduced set of models and convert to a matrix for easier indexing
use_set <- as.matrix(full_set[-ii,]) # 38 models

## number of models in set
(n_mods <- nrow(use_set)) # 38 models out of potential 64

## create empty matrix for storing results
mod_res <- matrix(NA, n_mods, 2)
colnames(mod_res) <- c("AIC", "BIC")

## fit models and store AIC & BIC
for(i in 1:n_mods) {
  if(i == 1) {
    fmla <- "Size ~ 1 + (1 | Observer) + (1 | Plot)"
  } else {
    fmla <- paste("Size ~ (1 | Observer) + (1 | Plot) +", paste(cov_names[use_set[i,]], collapse = " + "))
  }
  mod_fit <- lmer(as.formula(fmla), data = SCMUdf, REML = TRUE)
  mod_res[i,"AIC"] <- AIC(mod_fit)
  mod_res[i,"BIC"] <- BIC(mod_fit) 
}

## create empty matrix for storing results
delta_res <- matrix(NA, n_mods, 2)
colnames(delta_res) <- c("deltaAIC", "deltaBIC")

## convert IC to deltaIC
delta_res[,"deltaAIC"] <- mod_res[,"AIC"] - min(mod_res[,"AIC"])
delta_res[,"deltaBIC"] <- mod_res[,"BIC"] - min(mod_res[,"BIC"])
(delta_res <- round(delta_res, 2)) # round results

## create df with mod results
mp <- as.data.frame(use_set)

for (i in 1:length(mp)) {
   mp[[i]] <- str_replace(mp[[i]], "TRUE", colnames(mp)[i])
}

for (i in 1:length(mp)) {
   mp[[i]] <- str_replace(mp[[i]], "FALSE", " ")
}

mpfe <- mp %>%
  mutate(FEs = paste(EggOrder, ANCHL, BEUTI, NPGO, ONI, PDO, SST, sep = " "))

usmr <- mpfe %>%
  mutate(k = as.vector(rowSums(use_set) + 2)) %>% #2 check this
  mutate(modelno = 1:38) 

allm <- as.data.frame(delta_res) %>%
  mutate(modelno = 1:38) %>%
  arrange(deltaAIC) %>%
  left_join(usmr, by = "modelno") %>%
  dplyr::select(modelno, FEs, k, deltaAIC, deltaBIC)

## create df with top models
bestm <- allm %>%
  filter(deltaAIC <= 2) 
```
There are three competitive models. All three models include EggOrder and BEUTI as a predictor.

# Top Models
Here we look at the top three competitive models. 

## First Top Model
```{r bestmod1}
##run model
bm1 <- lmer(Size ~ EggOrder + BEUTI + NPGO + ONI + (1 | Observer) + (1 | Plot), data = SCMUdf, REML = TRUE)
## look at model output and estimates
summary(bm1)
coef(bm1)
ranef(bm1)
model.matrix(bm1)
```


## Second Top Model
```{r bestmod2}
##run model
bm2 <- lmer(Size ~ EggOrder + ANCHL + BEUTI + ONI + (1 | Observer) + (1 | Plot), data = SCMUdf, REML = TRUE)

## look at model output and estimates
summary(bm2)
coef(bm2)
ranef(bm2)
model.matrix(bm2)
```


## Third Top Model
```{r bestmod3}
##run model
bm3 <- lmer(Size ~ EggOrder + ANCHL + BEUTI + SST + (1 | Observer) + (1 | Plot), data = SCMUdf, REML = TRUE)

## look at model output and estimates
summary(bm3)
coef(bm3)
ranef(bm3)
model.matrix(bm3)
```

# Model Diagnostics
These diagnostics are done for the first top model only but can be repeated for the other 2 models. 

## Residuals/Fitted Plots

### Histogram of Predicted Values
```{r d1}
## extract predicted values and plot
preds <- predict(bm1)
ggplot() + 
  geom_histogram(mapping = aes(preds), bins = 10) + # set bins 
  theme_minimal()
```
Since we assumed our data are normal, we want to see an approximately normal distribution of predicted values.

### Histogram of Residuals
```{r d2}
## extract residuals and plot
resids <- residuals(bm1)
ggplot() + 
  geom_histogram(mapping = aes(resids), bins = 20) + 
  theme_minimal()
```
Since we assumed our data are normal, we want to see an approximately normal distribution of residuals (differences between observed and predicted values of data).

### Model Coefficients
```{r d3}
## extract coeffs and random effects
coef(bm1) # this include fixed and random effects
ranef_obs <- ranef(bm1)$Observer # observer random effect only
ranef_pl <- ranef(bm1)$Plot # plot random effect only

## look at data going into random effects
table(SCMUdf$Observer)
table(SCMUdf$Plot)
```
We can extract our model coefficients (for fixed and random effects) and look at them. 

### Q-Q Plots
```{r d4}
# qq resids
qqnorm(resids, main = "QQ plot (residuals)", las = 1, pch = 16)
qqline(resids)

# qq Plot RE
qqnorm(unlist(ranef_pl), main = "QQ plot (Plot RE)", las = 1, pch = 16)
qqline(unlist(ranef_pl))

# qq Observer RE
qqnorm(unlist(ranef_obs), main = "QQ plot (Observer RE)", las = 1, pch = 16)
qqline(unlist(ranef_obs))
```
We want our points to fall approximately on the diagonal lines. 

### Fitted v Residuals
```{r d5}
## plot residuals versus fitted values
yh <- fitted(bm1)
plot(yh, resids, las = 1, pch = 16,
     xlab = "Fitted", ylab = "Residuals",
     main = "Residuals vs fitted")
abline(h=0, lty = "dashed")
```
We assume our errors are normally distributed with constant variance. We want this plot to look like a scattershot of points, without any evidence of trends. 

## Levene's test
We can formally test the assumption of homogenous variance via the Levene's Test, which compares the absolute values of the residuals among groups. 
```{r lev}
## split residuals into 2 groups
g1 <- resids[yh <= median(yh)]
g2 <- resids[yh > median(yh)]

## Levene's test
var.test(g1, g2)
```
There is no justification to reject the null hypothesis that the residuals are equal. F is close to 1 and it is within the 95% confidence interval. 

## Autocorrelation
We also assume our errors are independent (e.g., not correlated). An ACF plot can be used to look for autocorrelation. 
```{r acf}
# calculate the ACF for lags between 1 and 10 
autocorrelation <- acf(resids, lag.max= 10, plot = FALSE)

# Plot figure
plot(autocorrelation,
     main="Autocorrelation",
     xlab="Lag Parameter",
     ylab="ACF")
```
The first value with 0 lag will always be autocorrelated because it's stacked on itself. But after that, we want to see the values within the blue dotted lines. There does not appear to be autocorrelation in the residuals. 

## Goodness of Fit
Review with Sarah***
```{r gof}
## Goodness of fit
## Pearson's X^2 statistic
true <- SCMUdf$Size # 'true' egg size values
nn <- nrow(SCMUdf) # number of observations
X2 <- sum((true - yh)^2/yh)
degf <- nn-6 # 4 fixed effects, 2 random effects

## likelihood ratio test
pchisq(X2, df = degf, lower.tail = FALSE)
```

## Likelihood Ratio Tests
Review with Sarah***
```{r likelihoodratio}
## Likelihood ratio tests  
## top model
bm1 <- lmer(Size ~ EggOrder + BEUTI + NPGO + ONI + (1 | Observer) + (1 | Plot), data = SCMUdf, REML = TRUE)

## run model with plot RE only
bm_plot <- lmer(Size ~ EggOrder + BEUTI + NPGO + ONI +  (1 | Plot), data = SCMUdf, REML = TRUE)

## run model with obs RE only
bm2 <- lmer(Size ~ EggOrder + BEUTI + NPGO + ONI + (1 | Observer), data = SCMUdf, REML = TRUE)

bm_obs1 <- lmer(Size ~ EggOrder + BEUTI + NPGO + ONI + (1 | Observer), data = SCMUdf, REML = FALSE)

bm_null <- lm(Size ~ EggOrder + BEUTI + NPGO + ONI , data = SCMUdf)

## conduct an LRT to see if the variance of the Plot RE is contributing useful info
test_1 <- 2 * (logLik(bm1) - logLik(bm_obs))
pchisq(as.numeric(test_1), df = 1, lower.tail = FALSE)
# There is support for inclusion of Plot as an RE

## check for contribution of Obs RE
test_2 <- 2 * (logLik(bm1) - logLik(bm_plot))
pchisq(as.numeric(test_2), df = 1, lower.tail = FALSE)
# There is support for inclusion of Obs as an RE

## Bootstrapping  to test for evidence against including multiple random effects in the same model
## set random seed 
set.seed(514)

## fit null model with no RE's 
nbm <- lm(Size ~ EggOrder + BEUTI + NPGO + ONI, data = SCMUdf)

## calculate likelihood ratio (difference in log-likelihood)
lambda <- 2 * (logLik(bm1) - logLik(nbm))

## number of bootstrapped samples
nb <- 1000

## empty vector for storing LRT statistics
LRT_boot <- rep(NA, nb)

## bootstrapping
for(i in 1:nb) { # repeat nb times
  sim_data <- unlist(simulate(nbm)) # simulate data from null model
  m_null <- lm(sim_data ~ EggOrder + BEUTI + NPGO + ONI, data = SCMUdf) # fit null model to sim data 
  m_alt <- lmer(sim_data ~ EggOrder + BEUTI + NPGO + ONI + (1 | Observer) + (1 | Plot), data = SCMUdf, REML = TRUE) # fit RE model
  LRT_boot[i] <- as.numeric(2*(logLik(m_alt) - logLik(m_null))) # calculate likelihood ratio 
} # boundary (singular) fit: see ?isSingular

## calculate approximate p-value
mean(LRT_boot > lambda)


library(boot)
library(RLRsim)

exactRLRT(bm_obs, bm1, bm_plot)

exactRLRT(bm_plot, bm1, bm_obs)

exactLRT(bm_obs1,bm_null)

```

# Identifying Outliers
https://qerm514.github.io/website/labs/week_03/diagnostics_and_errors.html#unusual_observations
https://qerm514.github.io/website/homework/week_03/hw_03_diagnostics_key.pdf
Calculate the studentized residuals to look for outliers
```{r outliers}
## get studentized residuals
(stud_e <- rstudent(bm1))

## get sample size
n <- nrow(SCMUdf)

## Bonferroni correction: alpha/n
alpha <- 0.05/n

## critical t value
degf <- n - length(coef(bm1))-1 # should be more due to REs?
t_crit <- qt(1 - alpha/2, degf)

## compare t_stud to t_crit
sum(stud_e > t_crit, na.rm = TRUE)
```

## Cook's Distance
```{r cook}
## Cook's D
cook <- cooks.distance(bm1)

# Plot the Cook's Distance using the traditional 4/n criterion
sample_size <- nrow(SCMUdf)
plot(cook, pch="*", cex=2, main="Influential Obs by Cooks distance")  # plot cook's distance
abline(h = 4/sample_size, col="red")  # add cutoff line
text(x=1:length(cook)+1, y=cook, labels=ifelse(cook>4/sample_size, names(cook),""), col="red")  # add labels
```

# Confidence Intervals
```{r conf}
# predict values
pred <- predict(bm1,re.form = NA)

# Bootstrap CI
boot <- bootMer(bm1, predict, nsim = 100, re.form = NA)
std.err <- apply(boot$t, 2, sd)
CI.lo <- pred - std.err*1.96
CI.hi <- pred + std.err*1.96

# Plot?
```

# Prediction