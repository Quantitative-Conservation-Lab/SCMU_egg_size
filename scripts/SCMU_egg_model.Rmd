---
title: "Scripps's Murrelet Egg Size model"
author: "Amelia J. DuVall & Marcela Todd"
date: "4/11/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

## load libraries
library(here)
library(tidyverse)
library(janitor)
library(ggplot2)
library(lubridate)
library(viridis)
library(lme4)
library(faraway)
library(sjPlot)
```

This is `r paste0("v.", (Sys.Date()))`

#TODO
- Calculate confidence intervals
- Check if outliers are influential
- Prediction
- Diagnostics
- Likelihood ratio tests for random effects
- Correlation of fixed effects
- Multi-modal inference?

# Introduction
This document details steps taken to model Scripps's Murrelet (*Synthliboramphus scrippsi*) egg size at Santa Barbara Island within Channel Islands National Park from 2009-2017.  

# Load and format data 
```{r data}
egg <- read_csv(here("data", "SCMU_egg_data.csv"))
covars <- read_csv(here("data", "covariates", "covars.csv"))

## join covariate data with egg data by year
df <- left_join(egg, covars, by = "Year") %>%
  filter(TrueOrder == TRUE) %>% # egg order known only
  select(Year, Observer, Plot, Size, EggOrder, ANCHL, BEUTI, NPGO, ONI, PDO, SST)
```

# Null Intercept-Only Model
This model includes observer and plot as random effects, but does not include any covariates.
```{r null_model}
## run model
nm <- lmer(Size ~ 1 + (1 | Observer) + (1 | Plot), data = df)

## look at model output and estimates
sumary(nm)
coef(nm) # these are the coefficients
ranef(nm) # these are the random effects
## you can store the model results to objects
obs.ranef <- ranef(nm)$Observer 
plot.ranef <- ranef(nm)$Plot
## the mean of these values should be close to 0
mean(obs.ranef[[1]])
mean(plot.ranef[[1]])

## quick model diagnostics
## extract predicted values and plot
preds <- predict(nm) 
ggplot() + 
  geom_histogram(mapping = aes(preds)) + 
  theme_minimal() 
# we want these to look normally distributed

## extract residuals and plot
resids <- residuals(nm) 
ggplot() + 
  geom_histogram(mapping = aes(resids)) + 
  theme_minimal()
# we want these to look normally distributed

## Q-Q Plots
# ## set plot area
# par(mai = c(0.9, 0.9, 0.6, 0.1),
#     omi = c(0, 0, 0, 0),
#     mfrow = c(1,2), cex.lab = 1.2)

# qq resids
qqnorm(resids, main = "QQ plot (residuals)", las = 1, pch = 16)
qqline(resids)

## plot residuals versus fitted values
yh <- fitted(nm)
plot(yh, resids, las = 1, pch = 16,
     xlab = "Fitted", ylab = "Residuals",
     main = "Residuals vs fitted")
abline(h=0, lty = "dashed")
```

# Egg Order-only Model
This model includes observer and plot as random effects and egg order as a fixed effect. 
```{r null_model}
## run the model
order.mod <- lmer(Size ~ EggOrder + (1 | Observer) + (1 | Plot), data = df)

## look at model summary and estimates
sumary(order.mod)
coef(summary(order.mod))
VarCorr(order.mod)
ranef(order.mod)
```

# Fit Candidate Models
```{r mods}
## create data frame specifying predictors to include
predictors <- as.data.frame(matrix(c(FALSE, TRUE), 2, 7)) # 7 potential predictors (includes EggOrder)

## add column names
cov_names <- colnames(predictors) <- colnames(df[,5:11])

## create set of all possible combinations
full_set <- expand.grid(predictors) # 128 combinations

## select models with correlated predictors
ii <- which(full_set$ANCHL + full_set$NPGO == 2 |
              full_set$BEUTI + full_set$PDO == 2 |
              full_set$NPGO + full_set$SST == 2 |
              full_set$ONI + full_set$PDO == 2 |
              full_set$ONI + full_set$SST == 2 |
              full_set$PDO + full_set$SST == 2 ) # 90 models

## create reduced set of models and convert to a matrix for easier indexing
use_set <- as.matrix(full_set[-ii,]) # 38 models

## number of models in set
(n_mods <- nrow(use_set)) # 38 models out of potential 64

## create empty matrix for storing results
mod_res <- matrix(NA, n_mods, 2)
colnames(mod_res) <- c("AIC", "BIC")

## fit models and store AIC & BIC
for(i in 1:n_mods) {
  if(i == 1) {
    fmla <- "Size ~ 1 + (1 | Observer) + (1 | Plot)"
  } else {
    fmla <- paste("Size ~ (1 | Observer) + (1 | Plot) +", paste(cov_names[use_set[i,]], collapse = " + "))
  }
  mod_fit <- lmer(as.formula(fmla), data = df)
  mod_res[i,"AIC"] <- AIC(mod_fit)
  mod_res[i,"BIC"] <- BIC(mod_fit) 
}

## create empty matrix for storing results
delta_res <- matrix(NA, n_mods, 2)
colnames(delta_res) <- c("deltaAIC", "deltaBIC")

## convert IC to deltaIC
delta_res[,"deltaAIC"] <- mod_res[,"AIC"] - min(mod_res[,"AIC"])
delta_res[,"deltaBIC"] <- mod_res[,"BIC"] - min(mod_res[,"BIC"])
(delta_res <- round(delta_res, 2)) # round results

## create df with mod results
mp <- as.data.frame(use_set)

for (i in 1:length(mp)) {
   mp[[i]] <- str_replace(mp[[i]], "TRUE", colnames(mp)[i])
}

for (i in 1:length(mp)) {
   mp[[i]] <- str_replace(mp[[i]], "FALSE", " ")
}

mpfe <- mp %>%
  mutate(FEs = paste(EggOrder, ANCHL, BEUTI, NPGO, ONI, PDO, SST, sep = " "))

usmr <- mpfe %>%
  mutate(k = as.vector(rowSums(use_set) + 2)) %>% #2 check this
  mutate(modelno = 1:38) 

allm <- as.data.frame(delta_res) %>%
  mutate(modelno = 1:38) %>%
  arrange(deltaAIC) %>%
  left_join(usmr, by = "modelno") %>%
  dplyr::select(modelno, FEs, k, deltaAIC, deltaBIC)

## create df with top models
bestm <- allm %>%
  filter(deltaAIC <= 2) 
```
There are three competitive models. All three models include BEUTI as a predictor.

# Top Models
Here we look at the top three competitive models. 

## First Top Model
```{r bestmod1}
##run model
bm1 <- lmer(Size ~ EggOrder + BEUTI + NPGO + ONI + (1 | Observer) + (1 | Plot), data = df)
## look at model output and estimates
summary(bm1)
coef(bm1)
ranef(bm1)
model.matrix(bm1)
```


## Second Top Model
```{r bestmod2}
##run model
bm2 <- lmer(Size ~ EggOrder + ANCHL + BEUTI + ONI + (1 | Observer) + (1 | Plot), data = df)

## look at model output and estimates
summary(bm2)
coef(bm2)
ranef(bm2)
model.matrix(bm2)
```


## Third Top Model
```{r bestmod3}
##run model
bm3 <- lmer(Size ~ EggOrder + ANCHL + BEUTI + SST + (1 | Observer) + (1 | Plot), data = df)

## look at model output and estimates
summary(bm3)
coef(bm3)
ranef(bm3)
model.matrix(bm3)
```


# Model Diagnostics
These diagnostics are done for the first top model only but can be repeated for the other 2 models. 

## Residuals/Fitted Plots
```{r diagnostics}
## extract predicted values and plot
preds <- predict(bm1)
ggplot() + 
  geom_histogram(mapping = aes(preds)) + 
  theme_minimal()

## extract residuals and plot
resids <- residuals(bm1)
ggplot() + 
  geom_histogram(mapping = aes(resids)) + 
  theme_minimal()

## extract coeffs and random effects
coef(bm1)
ranef_obs <- ranef(bm1)$Observer
ranef_pl <- ranef(bm1)$Plot

## estimated mean egg size
eta <- predict(bm1)
mean(eta) # is this right?

## Q-Q Plots
# qq resids
qqnorm(resids, main = "QQ plot (residuals)", las = 1, pch = 16)
qqline(resids)

# qq Plot RE
qqnorm(unlist(ranef_pl), main = "QQ plot (Plot RE)", las = 1, pch = 16)
qqline(unlist(ranef_pl))

# qq Observer RE
qqnorm(unlist(ranef_obs), main = "QQ plot (Observer RE)", las = 1, pch = 16)
qqline(unlist(ranef_obs))

## plot residuals versus fitted values
yh <- fitted(bm1)
plot(yh, resids, las = 1, pch = 16,
     xlab = "Fitted", ylab = "Residuals",
     main = "Residuals vs fitted")
abline(h=0, lty = "dashed")
```

## Levene's test
```{r lev}
## Levene's test
## split residuals into 2 groups
g1 <- resids[yh <= median(yh)]
g2 <- resids[yh > median(yh)]

## Levene's test
var.test(g1, g2)
```
There is no justification to reject the null hypothesis that the residuals are equal. F is close to 1 and it is within the 95% confidence interval. 

## Autocorrelation
```{r acf}
# calculate the ACF for lags between 1 and 10 
autocorrelation <- acf(resids, lag.max= 10, plot = FALSE)

# Plot figure
plot(autocorrelation,
     main="Autocorrelation",
     xlab="Lag Parameter",
     ylab="ACF")
```
There does not appear to be autocorrelation in the residuals. 

## Goodness of Fit
Review with Sarah
```{r gof}
## Goodness of fit
## Pearson's X^2 statistic
true <- df$Size # 'true' egg size values
nn <- nrow(df) # number of observations
X2 <- sum((true - yh)^2/yh)
df <- nn-6 # 4 fixed effects, 2 random effects

## likelihood ratio test
pchisq(X2, df = 868, lower.tail = FALSE)
# large p-value, cannot reject H_0
```

## Correlation among Random Effects
```{r recorr}
## get var(RE)
(var_re_site <- as.data.frame(VarCorr(bm1)))

## variance of random effects
sigma2_alpha <- var_re_site$vcov[1]
## variance of residuals
sigma2_epsilon <- var_re_site$vcov[2]
## calculate the correlation among RE's
rho <- sigma2_alpha / (sigma2_alpha + sigma2_epsilon)
round(rho, 2)
```

## Likelihood Ratio Tests
```{r likelihoodratio}
## Likelihood ratio tests  
## run model with plot RE only
bm_plot <- lmer(Size ~ EggOrder + BEUTI + NPGO + ONI +  (1 | Plot), data = df)
## run model with obs RE only
bm_obs <- lmer(Size ~ EggOrder + BEUTI + NPGO + ONI + (1 | Observer), data = df)
## run model with both REs (same as top model) bm1

## conduct an LRT to see if the variance of the Obs RE is contributing useful info
test_1 <- 2 * (logLik(bm1) - logLik(bm_obs))
pchisq(as.numeric(test_1), df = 1, lower.tail = FALSE)
# There is support for inclusion of Obs as an RE

## check for contribution of Plot RE
test_2 <- 2 * (logLik(bm1) - logLik(bm_plot))
pchisq(as.numeric(test_2), df = 1, lower.tail = FALSE)
# There is support for inclusion of Plot as an RE

## Bootstrapping  to test for evidence against including multiple random effects in the same model
## set random seed 
set.seed(514)

## fit null model with no RE's 
nbm <- lm(Size ~ EggOrder + BEUTI + NPGO + ONI, data = df)

## calculate likelihood ratio (difference in log-likelihood)
lambda <- 2 * (logLik(bm1) - logLik(nbm))

## number of bootstrapped samples
nb <- 1000

## empty vector for storing LRT statistics
LRT_boot <- rep(NA, nb)

## bootstrapping
for(i in 1:nb) { # repeat nb times
  sim_data <- unlist(simulate(nbm)) # simulate data from null model
  m_null <- lm(sim_data ~ EggOrder + BEUTI + NPGO + ONI, data = df) # fit null model to sim data 
  m_alt <- lmer(sim_data ~ EggOrder + BEUTI + NPGO + ONI + (1 | Observer) + (1 | Plot), data = df) # fit RE model
  LRT_boot[i] <- as.numeric(2*(logLik(m_alt) - logLik(m_null))) # calculate likelihood ratio 
} # boundary (singular) fit: see ?isSingular

## calculate approximate p-value
mean(LRT_boot > lambda)
# none of the bootstrapped samples had a test statistic larger than the original value of lambda
```

# Multi-modal Inference
https://qerm514.github.io/website/labs/week_05/model_selection.html#multi-model_inference
```{r mminf}
## empty matrix for storing coefficients
## we'll fill it with 0's and replace them with the param estimates
mod_coef <- matrix(0, n_mods, 1 + ncol(df))
colnames(mod_coef) <- c("Intercept", colnames(df))

## fit models & store AIC & BIC
for(i in 1:n_mods) {
  if(i == 1) {
    fmla <- "Species ~ 1"
  } else {
    fmla <- paste("Species ~", paste(cov_names[use_set[i,]], collapse = " + "))
  }
  mod_fit <- lm(as.formula(fmla), data = gala)
  mod_coef[i, c(TRUE, use_set[i,])] <- coef(mod_fit)
}

## calculate weighted coefs
wtd_coef <- mod_coef * wts
(avg_coef <- colSums(wtd_coef))

```

# Identifying Outliers
https://qerm514.github.io/website/labs/week_03/diagnostics_and_errors.html#unusual_observations
https://qerm514.github.io/website/homework/week_03/hw_03_diagnostics_key.pdf
Calculate the studentized residuals to look for outliers
```{r outliers}
## get studentized residuals
(stud_e <- rstudent(bm1))

## get sample size
n <- nrow(df)

## Bonferroni correction: alpha/n
alpha <- 0.05/n

## critical t value
degf <- n - length(coef(bm1))-1 # should be more due to REs?
t_crit <- qt(1 - alpha/2, degf)

## compare t_stud to t_crit
sum(stud_e > t_crit, na.rm = TRUE)
```

## Cook's Distance
```{r cook}
## Cook's D
cook <- cooks.distance(bm1)

# Plot the Cook's Distance using the traditional 4/n criterion
sample_size <- nrow(df)
plot(cook, pch="*", cex=2, main="Influential Obs by Cooks distance")  # plot cook's distance
abline(h = 4/sample_size, col="red")  # add cutoff line
text(x=1:length(cook)+1, y=cook, labels=ifelse(cook>4/sample_size, names(cook),""), col="red")  # add labels

```